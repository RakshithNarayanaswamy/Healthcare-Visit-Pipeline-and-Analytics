{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7daade91-7c01-48d4-aaaa-0f7e7774e220",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark import pipelines as dp\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b46ec11-d1d6-40ce-8f31-a2c6908d67cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.view\n",
    "def silver_patients_cdf_type2_stage():\n",
    "    df = spark.readStream.table(\"LIVE.patients_type2_stage\")\n",
    "    df = df.withColumn(\"start_dt\", col(\"_commit_timestamp\"))\n",
    "    df = df.withColumn(\"end_dt\", lit(None).cast(\"timestamp\"))\n",
    "    df = df.withColumn(\"is_active\", lit(\"Y\"))\n",
    "    df = df.withColumn(\"load_dt\", current_timestamp())\n",
    "    return df\n",
    "\n",
    "@dlt.view\n",
    "def silver_providers_cdf_type2_stage():\n",
    "    df = spark.readStream.table(\"LIVE.providers_type2_stage\")\n",
    "    df = df.withColumn(\"start_dt\", col(\"_commit_timestamp\"))\n",
    "    df = df.withColumn(\"end_dt\", lit(None).cast(\"timestamp\"))\n",
    "    df = df.withColumn(\"is_active\", lit(\"Y\"))\n",
    "    df = df.withColumn(\"load_dt\", current_timestamp())\n",
    "    return df\n",
    "\n",
    "@dlt.view\n",
    "def silver_encounters_cdf_type2_stage():\n",
    "    df = spark.readStream.table(\"LIVE.encounters_type2_stage\")\n",
    "    df = df.withColumn(\"start_dt\", col(\"_commit_timestamp\"))\n",
    "    df = df.withColumn(\"end_dt\", lit(None).cast(\"timestamp\"))\n",
    "    df = df.withColumn(\"is_active\", lit(\"Y\"))\n",
    "    df = df.withColumn(\"load_dt\", current_timestamp())\n",
    "    return df\n",
    "\n",
    "@dlt.view\n",
    "def silver_conditions_cdf_type2_stage():\n",
    "    df = spark.readStream.table(\"LIVE.conditions_type2_stage\")\n",
    "    df = df.withColumn(\"start_dt\", col(\"_commit_timestamp\"))\n",
    "    df = df.withColumn(\"end_dt\", lit(None).cast(\"timestamp\"))\n",
    "    df = df.withColumn(\"is_active\", lit(\"Y\"))\n",
    "    df = df.withColumn(\"load_dt\", current_timestamp())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "497ea716-3395-4476-8f1e-ed51b0df5dcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dlt.create_streaming_table(\"gold_patients_cdf_streaming_type2\")\n",
    "dlt.apply_changes(\n",
    "    target = \"gold_patients_cdf_streaming_type2\",\n",
    "    source = \"silver_patients_cdf_type2_stage\",\n",
    "    keys = [\"patient_id\"],\n",
    "    sequence_by = \"start_dt\",\n",
    "    ignore_null_updates = True,\n",
    "    except_column_list = [\"_change_type\", \"_commit_version\", \"__START_AT\", \"__END_AT\"],\n",
    "    stored_as_scd_type = 1\n",
    ")\n",
    "\n",
    "dlt.create_streaming_table(\"gold_providers_cdf_streaming_type2\")\n",
    "dlt.apply_changes(\n",
    "    target = \"gold_providers_cdf_streaming_type2\",\n",
    "    source = \"silver_providers_cdf_type2_stage\",\n",
    "    keys = [\"doctor_id\"],\n",
    "    sequence_by = struct(\"_commit_timestamp\"),\n",
    "    ignore_null_updates = True,\n",
    "    apply_as_deletes = expr(\"_change_type = 'delete'\"),\n",
    "    except_column_list = [\"_change_type\",\"_commit_version\", \"__START_AT\", \"__END_AT\"],\n",
    "    stored_as_scd_type = 1\n",
    ")\n",
    "\n",
    "dlt.create_streaming_table(\"gold_encounters_cdf_streaming_type2\")\n",
    "dlt.apply_changes(\n",
    "    target = \"gold_encounters_cdf_streaming_type2\",\n",
    "    source = \"silver_encounters_cdf_type2_stage\",\n",
    "    keys = [\"visit_id\"],\n",
    "    sequence_by = struct(\"_commit_timestamp\"),\n",
    "    ignore_null_updates = True,\n",
    "    apply_as_deletes = expr(\"_change_type = 'delete'\"),\n",
    "    except_column_list = [\"_change_type\",\"_commit_version\", \"__START_AT\", \"__END_AT\"],\n",
    "    stored_as_scd_type = 1\n",
    ")\n",
    "\n",
    "dlt.create_streaming_table(\"gold_conditions_cdf_streaming_type2\")\n",
    "dlt.apply_changes(\n",
    "    target = \"gold_conditions_cdf_streaming_type2\",\n",
    "    source = \"silver_conditions_cdf_type2_stage\",\n",
    "    keys = [\"visit_id\", \"DiagnosisCode\"],\n",
    "    sequence_by = struct(\"_commit_timestamp\"),\n",
    "    ignore_null_updates = True,\n",
    "    apply_as_deletes = expr(\"_change_type = 'delete'\"),\n",
    "    except_column_list = [\"_change_type\",\"_commit_version\", \"__START_AT\", \"__END_AT\"],\n",
    "    stored_as_scd_type = 1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Stage_2_gold_scd2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}